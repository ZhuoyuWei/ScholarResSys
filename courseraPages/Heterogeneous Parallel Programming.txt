{"about_the_course":"<p>All computing\nsystems, from mobile to supercomputers, are becoming heterogeneous, massively\nparallel\u00a0computers for higher power efficiency and\u00a0computation\nthroughput. While the computing community is racing to build tools and\nlibraries to\u00a0ease the use of these systems, effective and confident\nuse\u00a0of these systems will always require knowledge about low-level\nprogramming\u00a0in these systems. This course is designed for students to\nlearn the essence\u00a0of low-level programming interfaces and how to use these\ninterfaces to achieve application goals. CUDA C, with its good balance between\nuser control and verboseness, will serve as the teaching vehicle for the first\nhalf of the course. Students will then extend their learning into closely\nrelated programming interfaces such as OpenCL, OpenACC, and C++AMP.</p>\n\n<p><span><br>\nThe course is unique in that it is application oriented and only introduces the\nnecessary\u00a0underlying computer science and computer engineering knowledge for\nunderstanding.\u00a0It covers the concept of data parallel execution models,\nmemory models for managing locality, tiling techniques for reducing bandwidth\nconsumption, parallel algorithm patterns,\u00a0overlapping computation with\ncommunication, and a variety of\nheterogeneous parallel programming interfaces. The concepts learned in this\ncourse form a strong foundation for learning other types of parallel\nprogramming systems.</span></p>\n\n<br>","subtitle_languages_csv":"","other_description":"","photo":"https://s3.amazonaws.com/coursera/topics/hetero/large-icon.png","preview_link":null,"small_icon_hover":"https://s3.amazonaws.com/coursera/topics/hetero/small-icon.hover.png","large_icon":"https://s3.amazonaws.com/coursera/topics/hetero/large-icon.png","video":"SCGlbr1t628","university-ids":["illinois"],"video_baseurl":"https://d1a2y8pfnfh44t.cloudfront.net/SCGlbr1t628/","id":129,"universities":[{"rectangular_logo_svg":"https://coursera-university-assets.s3.amazonaws.com/58/6401c0ebc5e834eed7f5017d6d80fd/illinois-svg.svg","wordmark":null,"website_twitter":"Illinois_Alma","china_mirror":1,"favicon":"https://coursera-university-assets.s3.amazonaws.com/2b/57d79bc1eb5b081e6a1b3729782566/favicon.png","website_facebook":"illinois.edu","logo":"https://coursera-university-assets.s3.amazonaws.com/a9/ff5237ed042c63a02e67e2094e97c1/university-of-illinois-at-urbana-champaign.png","background_color":"","id":17,"location_city":"Cunningham","location_country":"US","location_lat":40.11058750000000000,"location":"Urbana, Illinois","primary_color":"#003C7D","abbr_name":"Illinois","website":"http://illinois.edu/","description":"The University of Illinois at Urbana-Champaign is a world leader in research, teaching and public engagement, distinguished by the breadth of its programs, broad academic excellence, and internationally renowned faculty and alumni. Illinois serves the world by creating knowledge, preparing students for lives of impact, and finding solutions to critical societal needs.","short_name":"illinois","landing_page_banner":"https://coursera-university-assets.s3.amazonaws.com/0c/2f1f169c0cd38f3f21bdb0a1fe56eb/illinois_large_banner.jpg.jpg","mailing_list_id":null,"website_youtube":"illinois1867","partner_type":1,"banner":"https://coursera-university-assets.s3.amazonaws.com/10/ee5f408bc287fd1603e822a78105d4/banner-illinois.jpg","location_state":"IL","name":"University of Illinois at Urbana-Champaign","square_logo":"https://coursera-university-assets.s3.amazonaws.com/97/e9b2f7161cc868ac56168238e73cbf/wordmark_coursera-360.png","square_logo_source":"https://coursera-university-assets.s3.amazonaws.com/c4/02a8d66ad36ce995ab417f453f132a/wordmark_coursera-360.png","square_logo_svg":"https://coursera-university-assets.s3.amazonaws.com/5f/7ed0b6a31f200533af344013a411d7/wordmark_coursera-360.svg","location_lng":-88.20726969999998000,"home_link":"","class_logo":"https://coursera-university-assets.s3.amazonaws.com/5c/6d24b9e3be4b6e6cc1094c41a94e6d/Illinois-logo.png","display":true}],"self_service_course_id":null,"short_description":"This course introduces concepts, languages, techniques, and patterns for programming heterogeneous, massively parallel processors. Its contents and structure have been significantly revised based on the experience gained from its initial offering in 2012. It covers heterogeneous computing architectures, data-parallel programming models, techniques for memory bandwidth management, and parallel algorithm patterns.","description":"","short_name":"hetero","target_audience":1,"faq":"<ul>\n    <li><strong>Will I get a certificate for this course?</strong>\n        <p>Yes. Students who successfully complete the class will receive a certificate signed by the instructor.</p>\n    </li>\n\n    <li><strong>What resources will I need for this class?</strong> \n        <p>A laptop or desktop computer. GPU enabled hardware can be helpful but will not be required.</p>\n    </li>\n\n    <li><strong>Why not teach the whole course using OpenCL?</strong>\n        <p>While OpenCL is an industry standard and widely supported by many CPU and GPU vendors, it is much more complex and tedious to use than CUDA. The complexity and tedious details distract from the concepts and techniques that one should master. From\n            our experience, it is much more productive to use CUDA to teach the concepts and techniques. We will then teach the additional complexities of OpenCL so that students can comfortably apply all the concepts to OpenCL.</p>\n    </li>\n\n    <li><strong>How did the students do in the previous offering of the HPP Course?</strong> \n        <p> Out of the 9,908 students who did quizzes and programming assignments,.2,811 received Certificate of Achievement or Certificate of Distinction. </p>\n    </li>\n\n    <li><strong>What is the coolest thing I'll learn if I take this class?</strong>\n        <p>You will learn how to unleash the massive computing power from mobile processors to supercomputers for your applications.</p>\n\n    </li>\n</ul>","category-ids":["cs-systems","cs-programming"],"visibility":0,"course_syllabus":"<ul><li><span></span><b>Week One:</b> Introduction to Heterogeneous\nComputing, Overview of CUDA C, and Kernel-Based Parallel Programming, with lab tour\nand programming assignment of vector addition in CUDA C.<span></span></li><li><span>\u00a0</span><b>Week Two:</b> Memory Model for Locality, Tiling\nfor Conserving Memory Bandwidth, Handling Boundary Conditions, and Performance\nConsiderations, with\u00a0programming assignment of simple matrix-matrix multiplication\nin CUDA C.<span></span></li><li><span></span><b>Week Three:</b> Parallel Convolution Pattern, with\nprogramming assignment of tiled matrix-matrix multiplication in CUDA C.<span></span></li><li><span></span><b>Week Four:</b> Parallel Scan Pattern, with\nprogramming\u00a0assignment of parallel convolution in CUDA C<b>.</b></li><li><span></span><b>Week Five:</b> Parallel Histogram Pattern and\nAtomic Operations, with programming assignment of parallel scan in CUDA C.<span></span></li><li><span></span><b>Week Six:</b> Data Transfer and Task\nParallelism, with programming assignment of parallel histogram in CUDA C.<span></span></li><li><span></span><b>Week Seven:</b> Introduction to OpenCL,\nIntroduction to C++AMP, Introduction to OpenACC, with programming assignment of\nvector addition using streams in CUDA C.<span></span></li><li><span></span><b>Week Eight: </b>Course Summary,\nOther Related Programming Models \u2013Thrust,\u00a0Bolt, and CUDA FORTRAN, with\nprogramming assignment of simple matrix-matrix multiplication in choice of\nOpenCL, C++AMP, or OpenACC<b>.</b></li><li><b></b><span></span><b>Week Nine: </b>complete any\nremaining lab assignments, with optional, bonus programming assignments in choice\nof OpenCL, C++AMP, or OpenACC.\n\n</li>\n</ul>","course_format":"The class will\nconsist of weekly lecture videos, which are between 15 and 20 minutes in\nlength. There will also be weekly quizzes and programming assignments.<div>\n\n</div><br>","has_full_data":true,"small_icon":"https://s3.amazonaws.com/coursera/topics/hetero/small-icon.hover.png","suggested_readings":"<div>\n\n<p><span>Although the class is designed to be self-contained, students\nwanting to expand their knowledge beyond what we can cover in a one-quarter\nclass can find a much more extensive coverage of this topic in the book <a href=\"http://www.chegg.com/etextbooks/programming-massively-parallel-processors-2nd-edition-9780123914187-0123914183?trackid=1b099236&ii=1\"><span>Programming\nMassively Parallel Processors: A Hands-on Approach (Applications of GPU\nComputing Series) -\u00a0 2nd Edition</span></a></span>, by David Kirk\nand Wen-mei Hwu, published by Morgan Kaufmann (Elsevier), ISBN 0123814723.</p>\n\n</div><br>","instructor":"Wen-mei W. Hwu","categories":[{"id":11,"name":"Computer Science: Systems & Security","mailing_list_id":null,"short_name":"cs-systems","description":"Our wide range of courses allows students to explore topics from many different fields of study. Sign up for a class today and join our global community of students and scholars!"},{"id":12,"name":"Computer Science: Software Engineering","mailing_list_id":null,"short_name":"cs-programming","description":"Our wide range of courses allows students to explore topics from many different fields of study. Sign up for a class today and join our global community of students and scholars!"}],"estimated_class_workload":"6-8 hours/week","name":"Heterogeneous Parallel Programming","language":"en","university_logo_st":"","video_id":null,"courses":[{"grading_policy_distinction":"The final grade was calculated as 50% of quizzes (dropping the lowest quiz score) and 50% of MP1 - MP5 (dropping the lowest MP). In addition, MP6 is calculated as extra credit. Within the quiz category, all included quizzes are weighted equally. Within the MP category, all included MPs are also weighted equally. To receive a Statement of Distinction, one has to obtain >=85% of the maximum possible score.","ace_track_price_display":null,"signature_track_certificate_design_id":null,"ace_semester_hours":null,"start_day":28,"duration_string":"8 weeks","signature_track_last_chance_time":null,"signature_track_additional_notes":"","certificate_ready_user_id":null,"id":384,"start_month":11,"certificate_description":"The course covers data parallel execution models, locality, parallel algorithm patterns, and scalable programming using joint MPI-CUDA in large scale computing clusters. As part of the course work, students were required to complete 5 quizzes and 5 programming assignments.","start_date_string":"24 September 2012 ","chegg_session_id":"","signature_track_regular_price":null,"grades_release_date":"2013-02-18","certificates_ready":true,"signature_track_price":null,"statement_design_id":15,"signature_track_registration_open":false,"topic_id":129,"eligible_for_signature_track":false,"start_date":null,"status":0,"start_year":2012,"signature_track_certificate_combined_signature":"","end_date":null,"notified_subscribers":true,"instructors":[917653],"end_of_class_emails_sent":"2010-01-01","active":true,"eligible_for_certificates":true,"signature_track_certificate_signature_blurb":"","deployed":true,"ace_close_date":null,"name":"12-001","textbooks":[],"signature_track_open_time":null,"eligible_for_ACE":false,"grading_policy_normal":"The final grade was calculated as 50% of quizzes (dropping the lowest quiz score) and 50% of MP1 - MP5 (dropping the lowest MP). In addition, MP6 is calculated as extra credit. Within the quiz category, all included quizzes are weighted equally. Within the MP category, all included MPs are also weighted equally. To receive a Statement of Accomplishment, one has to obtain >=70% of the maximum possible score.","ace_open_date":null,"signature_track_last_refund_date":null,"home_link":"https://class.coursera.org/hetero-2012-001/","creator_id":null,"proctored_exam_completion_date":null,"university_logo":"","signature_track_close_time":null,"auth_review_completion_date":"2010-01-01"},{"grading_policy_distinction":"The final grade was calculated as 50% of quizzes (dropping the lowest quiz score) and 50% of MP1 - MP8 (dropping the lowest MP). In addition, MP9 is calculated as extra credit. Within the quiz category, all included quizzes are weighted equally. Within the MP category, all included MPs are also weighted equally. To receive a Statement of Distinction, one has to obtain >=85% of the maximum possible score.","ace_track_price_display":null,"signature_track_certificate_design_id":null,"ace_semester_hours":null,"start_day":6,"duration_string":"9 weeks","signature_track_last_chance_time":"2014-01-20","signature_track_additional_notes":"","certificate_ready_user_id":null,"id":970755,"start_month":1,"certificate_description":"The course covers data parallel execution models, memory models for locality, parallel algorithm patterns, and popular heterogeneous parallel programming interfaces. As part of the course work, students were required to complete 6 quizzes and 8 programming assignments.","start_date_string":null,"chegg_session_id":"","signature_track_regular_price":49.00,"grades_release_date":null,"certificates_ready":false,"signature_track_price":49.00,"statement_design_id":15,"signature_track_registration_open":true,"topic_id":129,"eligible_for_signature_track":true,"start_date":null,"status":1,"start_year":2014,"signature_track_certificate_combined_signature":"","end_date":null,"notified_subscribers":true,"instructors":[917653],"end_of_class_emails_sent":null,"active":false,"eligible_for_certificates":true,"signature_track_certificate_signature_blurb":"","deployed":true,"ace_close_date":null,"name":"002","textbooks":[],"signature_track_open_time":"2013-12-09","eligible_for_ACE":false,"grading_policy_normal":"The final grade was calculated as 50% of quizzes (dropping the lowest quiz score) and 50% of MP1 - MP8 (dropping the lowest MP). In addition, MP9 is calculated as extra credit. Within the quiz category, all included quizzes are weighted equally. Within the MP category, all included MPs are also weighted equally. To receive a Statement of Accomplishment, one has to obtain >=70% of the maximum possible score.","ace_open_date":null,"signature_track_last_refund_date":"2014-02-11","home_link":"https://class.coursera.org/hetero-002/","creator_id":1109835,"proctored_exam_completion_date":null,"university_logo":"","signature_track_close_time":"2014-01-28","auth_review_completion_date":null}],"about_the_instructor":"<img src=\"https://s3.amazonaws.com/coursera/topics/hetero/instructor-1.png\" height=\"284\" style=\"width: 227px;\" class=\"coursera-instructor-thumb\">\n<div>Wen-mei W. Hwu is a Professor and holds the Sanders-AMD Endowed Chair in the\u00a0Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign. His research interests are in the area of architecture, implementation,\u00a0compilation, and algorithms for parallel computing. He is the chief scientist of Parallel\u00a0Computing Institute and director of the IMPACT research group (<a href=\"http://impact.crhc.illinois.edu\" target=\"_blank\">impact.crhc.illinois.edu</a>). He is a co-founder and CTO of MulticoreWare. For his contributions in\u00a0research and teaching, he received the ACM SigArch Maurice Wilkes Award, the ACM\u00a0Grace Murray Hopper Award, the Eta Kappa Nu Holmes MacDonald Outstanding Teaching\u00a0Award, the CAM/IEEE ISCA Influential Paper Award, and the Distinguished Alumni\u00a0Award in Computer Science of the University of California, Berkeley. He is a fellow\u00a0of IEEE and ACM. He directs the UIUC CUDA Center of Excellence and serves as\u00a0one of the principal investigators of the $208M NSF Blue Waters Petascale computer\u00a0project. Dr. Hwu received his Ph.D. degree in Computer Science from the University of\u00a0California, Berkeley.</div>\n<div><br>\n<div>In 2007, Hwu teamed up with then NVIDIA Chief Scientist David Kirk to create a course\u00a0called Programming Massively Parallel Processors (<a href=\"https://ece408.hwu.crhc.illinois.edu\" target=\"_blank\">https://ece408.hwu.crhc.illinois.edu</a>).\u00a0Thousands of students worldwide follow the course through the web site each semester.\u00a0The course material has also been used by numerous universities including MIT, Stanford,\u00a0and Georgia Tech. Hwu and Kirk have also been teaching a VSCSE Summer School\u00a0version to science and engineering graduate students from all over the world. In 2008,\u00a050 graduates from 17 countries and three continents attended the summer school (<a href=\"http://www.greatlakesconsortium.org/events/GPUMulticore/\">http://www.greatlakesconsortium.org/events/GPUMulticore/</a>) in Urbana with another 60 participating\u00a0remotely. Students in the summer school come from diverse disciplines. In 2009, the summer\u00a0school was again fully subscribed with 160 students from multiple continents. The 2010 offering\u00a0was attended by 220 students at four sites linked with HD video. The 2011 attendance further\u00a0increased to 280 at 10 sites across the U.S. The 2012 summer school is projected to have more\u00a0than 320 students at 10 linked sites. Due to popular demand, Hwu and Kirk have also been\u00a0teaching abbreviated versions of their course globally, most recently at the Chinese Academy\u00a0of Science in 2008, Berkeley in 2010, Braga Portugal in 2010, and Chile in 2011. They have\u00a0also collaborated with UPC/Barcelona Supercomputing Center to offer an EU PUMPS summer\u00a0school in Barcelona every year since 2010. In February 2010, Hwu and Kirk published a\u00a0textbook on programming massively parallel processors. The book has been extremely popular,\u00a0with more than 10,000 copies sold to date. International editions and translations are available\u00a0in China, India, Japan, Russia, Spain, Portugal and Latin America. The second edition is\u00a0already in production.<br>\n<div></div>\n</div>\n<div></div>\n</div>","university_logo":"","course-ids":[384,970755],"display":true,"recommended_background":"Programming experience in C/C++."}

